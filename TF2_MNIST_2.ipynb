{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a channels dimension\n",
    "# 多增加第4個 dimension:\"channel\"\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#== tf.data API 來建立 input pipeline ==#\n",
    "#  * tf.data\n",
    "\n",
    "#1.\"from_tensor_slices\" 建立一個 Dataset Object\n",
    "#  在使用\"from_tensor_slices\"參數（x_train, y_train）是\n",
    "#  包含很多筆類型一樣的data,像這個例子有 60000筆data。\n",
    "#  不要跟\"from_tensor\"搞混了!\n",
    "\n",
    "#2.將training data做shuffle打亂 和 將batch size設定為 32\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(10000).batch(32)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#== 使用 Keras 自訂一個 Model ==#\n",
    "#  * tf.Keras.Model\n",
    "#  * tf.Keras.layers\n",
    "\n",
    "#1.建立一個 Class並繼承 tf.Keras.Model\n",
    "#2.__init__裡面我們可以自己設計每一層 Layer長什麼樣子，\n",
    "#  是哪種 Layer(Convolution, dense...)\n",
    "\n",
    "#3.call定義了這個 Model的 forward pass\n",
    "\n",
    "class MyModel(Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()    \n",
    "    # Define your layers here.\n",
    "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "    self.flatten = Flatten()\n",
    "    self.d1 = Dense(128, activation='relu')\n",
    "    self.d2 = Dense(10, activation='softmax')\n",
    "\n",
    "  def call(self, x):\n",
    "    # Define your forward pass here,\n",
    "    # using layers you previously defined (in __init__).\n",
    "    x = self.conv1(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#== 選擇 loss, optimizer和 metrics ==#\n",
    "#  * tf.keras.losses\n",
    "#  * tf.keras.optimizers\n",
    "#  * tf.keras.metrics\n",
    "\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#== train the model (定義)==#\n",
    "#  * tf.function\n",
    "#  * tf.GradientTape\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    \n",
    "    #\n",
    "    with tf.GradientTape() as tape:\n",
    "        # forward pass to get predictions\n",
    "        predictions = model(images)\n",
    "        # compute loss with the ground and our predictions\n",
    "        loss = loss_object(labels, predictions)\n",
    "    # compute gradient \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # back propagation\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#== test the model (定義)==#\n",
    "#  * tf.function\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    \n",
    "    # forward pass to get predictions\n",
    "    predictions = model(images)\n",
    "    # compute loss with the ground and our predictions\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0908 04:30:25.684524 139914416629568 base_layer.py:1772] Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.13473506271839142, Accuracy: 95.97666931152344, Test Loss: 0.06092844903469086, Test Accuracy: 98.11000061035156\n",
      "\n",
      "Epoch 2, Loss: 0.03951505571603775, Accuracy: 98.75333404541016, Test Loss: 0.054404206573963165, Test Accuracy: 98.29000091552734\n",
      "\n",
      "Epoch 3, Loss: 0.02091340534389019, Accuracy: 99.33333587646484, Test Loss: 0.05234690383076668, Test Accuracy: 98.37999725341797\n",
      "\n",
      "Epoch 4, Loss: 0.012101341038942337, Accuracy: 99.59666442871094, Test Loss: 0.05848024785518646, Test Accuracy: 98.3499984741211\n",
      "\n",
      "Epoch 5, Loss: 0.010396501049399376, Accuracy: 99.6500015258789, Test Loss: 0.05654916912317276, Test Accuracy: 98.43000030517578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#== 真正開始 train model ==#\n",
    "\n",
    "# 定義EPOCH數(整個dataset 拿來train過一次稱一個epoch)\n",
    "EPOCH = 5\n",
    "for epoch in range(EPOCH):\n",
    "    for images, labels in train_dataset:\n",
    "        train_step(images, labels)\n",
    "\n",
    "    for test_images, test_labels in test_dataset:\n",
    "        test_step(test_images, test_labels)    \n",
    "    \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}\\n'\n",
    "    print(template.format(epoch+1,\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result()*100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result()*100))\n",
    "\n",
    "    # Reset the metrics for the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
